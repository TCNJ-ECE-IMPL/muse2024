# Contents of the experiment directory:

**/tdms_data/:** 

Data obtained from NI Virtual Lab software. Copied from the tdms_data directory in the root of the repository

**/src/:**

Source code for the network. Copied from the src directory in the root of the repository

**/datasets/**

Output of prepare_dataset.py, processed versions of the original tdms data shuffled and partitioned.

**/models/:**

Collects the models created in the optuna trials, generated by network_optuna.py. Check the best model at the end of the study.log file created in /src/ by network_optuna.py to find the best model number, all others can be deleted.

These models are not trained yet and contain no weights, just hyperparameters. After being generated, they can be used by network.py to train.

**/checkpoints/:**

Collects checkpoints created when training the neural network, generated by network.py.

These checkpoints are trained and contain weights.

# Contents of the src directory:

**prepare_dataset.py:**

Reads data from the tdms files stored in /tdms_data/ and converts into TensorFlow dataset objects. Shuffles, partitions, and saves under /datasets/. This script is automatically run when new_experiment.sh is executed.

**network_functions.py:**

Contains helper functions used by network_optuna.py and network.py. Contains no main function and is not to be run independently

**network_optuna.py:**

Utilizes the optuna library to find ideal hyperparameters for the neural network based on the input data. Results found are recorded in /src/study.log, with the models being stored in /models/

**train_model.py:**

Trains the ideal model found in network_optuna.py

**network.py:**

Creates a network from scratch and runs. Usually contains a model based off of the best optuna trial, re-implemented to have greater control over layers.

**plot.py:**

Contains visualization tools for the network